{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee4536a-d0b6-48da-bf6c-21b99ba52bf1",
   "metadata": {},
   "source": [
    "Fetch and organize SNODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2bb57-df79-4598-a275-f516dcab26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import regionmask \n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import zarr\n",
    "from datetime import datetime, timedelta\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from validation import SNODAS, MountainHub, Elevation, utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d6cc3-63cb-4b19-886a-97a4ddb1cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2003,10,1)\n",
    "end_date = datetime(2004,10,1)\n",
    "ndays = end_date - start_date\n",
    "ndays.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca365c-f8fe-4acf-8ce0-3e451e896356",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_den = s_clm.output[‘scalarSWE’]/s_clm.output[‘scalarSnowDepth’]\n",
    "jrdn_den = s_jrdn.output[‘scalarSWE’]/s_jrdn.output[‘scalarSnowDepth’]\n",
    "thin_den = s_2layer.output[‘scalarSWE’]/s_2layer.output[‘scalarSnowDepth’]\n",
    "thick_den = s_thick.output[‘scalarSWE’]/s_thick.output[‘scalarSnowDepth’]clm_den.plot(label=‘CLM layering’)\n",
    "jrdn_den.plot(label=‘Jordan1991 layering’)\n",
    "thin_den.plot(label=‘Thin-2 layer’)\n",
    "thick_den.plot(label=‘Thick-2 layer’)\n",
    "plt.legend()\n",
    "plt.ylabel(‘Density (kg m^-3)’)\n",
    "plt.xlim(xmin = datetime.datetime(2011,3,3),xmax = datetime.datetime(2011,7,12))\n",
    "plt.savefig(“densityclose.png”, dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08288ef-40b2-41ec-ad41-97bc5813ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from SNODAS\n",
    "for date in (start_date + timedelta(n) for n in range(ndays.days)):\n",
    "    output_path = date.strftime('/home/spestana/data/SNODAS/SNODAS_%Y%m%d.nc')\n",
    "    if not os.path.exists(output_path):\n",
    "        print(output_path)\n",
    "        try:\n",
    "            snodas_ds = SNODAS.snodas_ds(date)\n",
    "            ut.save_netcdf(snodas_ds, output_path)\n",
    "        except Exception as err:\n",
    "            print(f\"Error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b6f40-71a4-4307-a9a9-fdb0deda9119",
   "metadata": {},
   "source": [
    "now that it is downloaded, we can work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea60714-f1ac-4dfd-821a-89885d8e6f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608ac99-5d03-4aef-abcc-f456042ce4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_start_cluster(\n",
    "    workers,\n",
    "    threads=1,\n",
    "    ip_address=None,\n",
    "    port=\":8786\",\n",
    "    open_browser=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Starts a dask cluster. Can provide a custom IP or URL to view the progress dashboard.\n",
    "    This may be necessary if working on a remote machine.\n",
    "    \"\"\"\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=workers,\n",
    "        threads_per_worker=threads,\n",
    "        #silence_logs=logging.ERROR,\n",
    "        dashboard_address=port,\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "\n",
    "    if ip_address:\n",
    "        if ip_address[-1] == \"/\":\n",
    "            ip_address = ip_address[:-1]  # remove trailing '/' in case it exists\n",
    "        port = str(cluster.dashboard_link.split(\":\")[-1])\n",
    "        url = \":\".join([ip_address, port])\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"Dask dashboard at:\", url)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"Dask dashboard at:\", cluster.dashboard_link)\n",
    "        url = cluster.dashboard_link\n",
    "\n",
    "    if port not in url:\n",
    "        if verbose:\n",
    "            print(\"Port\", port, \"already occupied\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Workers:\", workers)\n",
    "        print(\"Threads per worker:\", threads, \"\\n\")\n",
    "\n",
    "    if open_browser:\n",
    "        webbrowser.open(url, new=0, autoraise=True)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfaa5c4-7d06-4634-9e74-7285c13ca7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/spestana/data/SNODAS/'\n",
    "zarr_output_path = '/home/spestana/data/SNODAS/SNODAS_test.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e0bbf-cece-4497-852a-d8e4b914e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask_start_cluster(\n",
    "    workers=6,\n",
    "    threads=2,\n",
    "    ip_address='http://dshydro.ce.washington.edu',\n",
    "    port=\":8787\",\n",
    "    open_browser=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945df21d-8e7b-4684-b6fe-df0d124aad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Dask cluster so we can watch the dask dashboard\n",
    "## If this cell is not run, how many computer cores will be used?\n",
    "#workers = 6\n",
    "#ip_addres = 'http://dshydro.ce.washington.edu'\n",
    "#port=':8787'\n",
    "#threads = 2\n",
    "#cluster = LocalCluster(n_workers=workers, threads_per_worker=threads, dashboard_address=port)\n",
    "#client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b823e-1253-4244-a9f1-0b79d919da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the files may not be in a chronological order, we sort them so that the timeseries data we are creating will be in a chronological order.\n",
    "\n",
    "def get_start_date_from_SNODAS_filename(s):\n",
    "    datetime_str = s.split('_')[-1].split('.')[0] # format is YYYYMMDD\n",
    "    datetime_object = datetime.strptime(datetime_str, '%Y%m%d')\n",
    "    return datetime_object\n",
    "\n",
    "nc_files = sorted(\n",
    "    glob.glob(os.path.join(input_folder, '*.nc')),\n",
    "    key=get_start_date_from_SNODAS_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f26e55-051c-40ce-9091-f29e3a8d3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = [get_start_date_from_SNODAS_filename(s) for s in nc_files]\n",
    "files = nc_files\n",
    "\n",
    "for i,file in enumerate(files):\n",
    "    print(f\"Processing {i+1} of {len(files)}...\")\n",
    "    try:\n",
    "        ds = xr.open_dataset(file, decode_coords=\"all\")\n",
    "        ds = ds.assign_coords({\"time\": datetimes[i]})\n",
    "        ds = ds.expand_dims(\"time\")\n",
    "        ds = ds.reset_coords(drop=True)\n",
    "        da = ds['Band1']\n",
    "        new_file_name = file.replace(\n",
    "            \"/SNODAS/\",\n",
    "            \"/SNODAS_withtime/\",\n",
    "        )\n",
    "        da = da.rio.write_crs('EPSG:4326')\n",
    "        da.to_netcdf(new_file_name)\n",
    "    except Exception as err:\n",
    "        print(f\"Failed on {file}\")\n",
    "        print(f\"Error: {err}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eca431-61dc-400d-a8ea-21f1db5e6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_files = sorted(\n",
    "    glob.glob(os.path.join('/home/spestana/data/SNODAS_withtime/', '*.nc')),\n",
    "    key=get_start_date_from_SNODAS_filename\n",
    ")\n",
    "\n",
    "# Open all the raster files as a single dataset (combining them together)\n",
    "# Why did we choose chunks = 500? 100MB?\n",
    "# https://docs.xarray.dev/en/stable/user-guide/dask.html#optimization-tips\n",
    "ds = xr.open_mfdataset(nc_files, chunks={'time': 500})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02744a-0632-4a17-ab97-130bb816e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d49a22-1b5d-40e0-85cd-1a26852ccaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Band1 as a more indicative name: swe\n",
    "ds = ds.rename({'Band1': 'swe'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae5a22-8064-4537-b0af-bfb403c2f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.swe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2ab5c-83bd-493e-9735-1f8ad6c3e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask's rechunk documentation: https://docs.dask.org/en/stable/generated/dask.array.rechunk.html\n",
    "\n",
    "# 0:-1 specifies that we want the dataset to be chunked along the 0th dimension -- the time dimension, which means that each chunk will have all 40 thousand values in time dimension\n",
    "# 1:'auto', 2:'auto' and balance=True specifies that dask can freely rechunk along the latitude and longitude dimensions to attain blocks that have a uniform size\n",
    "ds['swe'].data.rechunk(\n",
    "    {0:-1, 1:'auto', 2:'auto'}, \n",
    "    block_size_limit=1e8, \n",
    "    balance=True\n",
    ")\n",
    "\n",
    "# Assign the dimensions of a chunk to variables to use for encoding afterwards\n",
    "t,y,x = ds['swe'].data.chunks[0][0], ds['swe'].data.chunks[1][0], ds['swe'].data.chunks[2][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3424d-77ed-4a69-b954-7b423450b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb0b32-2f3f-4432-95e8-f7122a9d258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68c730-3cd0-4f56-8e86-22d7f98135ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a shapefile, get the bounding box coords and subset dataset to that area\n",
    "sf_path = Path('/home/spestana/git/Skagit/raw_data/gis/SkagitRiver_BasinBoundary.shp').expanduser()\n",
    "sf = gpd.read_file(str(sf_path))\n",
    "minx, miny, maxx, maxy = sf.geometry[0].bounds\n",
    "ds = ds.sel(lat=slice(miny,maxy), lon=slice(minx,maxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8158e3-0a9a-4ba2-ba7f-7bfbbc8aeadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create an output zarr file and write these chunks to disk\n",
    "# if already exists, remove it here\n",
    "shutil.rmtree(zarr_output_path, ignore_errors=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89f68b-d56f-4e92-9f8e-976f9e4bc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4df21-21fc-4edf-aa9c-053fd65dfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['swe'].encoding = {'chunks': (t, y, x)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cb330-6fc1-4ab7-804f-059a48ee5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_zarr(zarr_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539096ef-9af0-434c-a705-15bba8be6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display \n",
    "source_group = zarr.open(zarr_output_path)\n",
    "source_array = source_group['swe']\n",
    "print(source_group.tree())\n",
    "print(source_array.info)\n",
    "del source_group\n",
    "del source_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91146d45-ea6f-4d69-be9d-70c18feb4998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "validation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
